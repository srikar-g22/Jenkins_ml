{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487dcff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpkl\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "import pickle as pkl\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def data_reading():\n",
    "    '''\n",
    "    reading dataset using padas dataframe\n",
    "    '''\n",
    "    dataset=pd.read_csv('./kidney_disease.csv')\n",
    "    dataset = dataset[~dataset['classification'].isin(['ckd\\t'])]\n",
    "    return dataset\n",
    "\n",
    "def finding_and_filling_null_values(df):\n",
    "    '''\n",
    "    Replacing the int column null values with mean and categorical columns with mode\n",
    "    '''\n",
    "    df['age'].fillna((df['age'].mean()), inplace=True)\n",
    "    df['bp'].fillna((df['bp'].mean()), inplace=True)\n",
    "    df['sg'].fillna((df['sg'].mean()), inplace=True)\n",
    "    df['al'].fillna((df['al'].mean()), inplace=True)\n",
    "    df['su'].fillna((df['su'].mean()), inplace=True)\n",
    "    df['bgr'].fillna((df['bgr'].mean()), inplace=True)\n",
    "    df['bu'].fillna((df['bu'].mean()), inplace=True)\n",
    "    df['sc'].fillna((df['sc'].mean()), inplace=True)\n",
    "    df['sod'].fillna((df['sod'].mean()), inplace=True) \n",
    "    df['pot'].fillna((df['pot'].mean()), inplace=True)\n",
    "    df['hemo'].fillna((df['hemo'].mean()), inplace=True)\n",
    "    \n",
    "    df['rbc'].fillna((df['rbc'].mode()[0]), inplace=True)\n",
    "    df['pc'].fillna((df['pc'].mode()[0]), inplace=True)\n",
    "    df['pcc'].fillna((df['pcc'].mode()[0]), inplace=True)\n",
    "    df['ba'].fillna((df['ba'].mode()[0]), inplace=True)\n",
    "    df['pcv'].fillna((df['pcv'].mode()[0]), inplace=True)\n",
    "    df['wc'].fillna((df['wc'].mode()[0]), inplace=True)\n",
    "    df['rc'].fillna((df['rc'].mode()[0]), inplace=True)\n",
    "    df['htn'].fillna((df['htn'].mode()[0]), inplace=True)\n",
    "    df['dm'].fillna((df['dm'].mode()[0]), inplace=True)\n",
    "    df['cad'].fillna((df['cad'].mode()[0]), inplace=True)\n",
    "    df['appet'].fillna((df['appet'].mode()[0]), inplace=True)\n",
    "    df['pe'].fillna((df['pe'].mode()[0]), inplace=True)\n",
    "    df['ane'].fillna((df['ane'].mode()[0]), inplace=True) \n",
    "    return df\n",
    "\n",
    "def finding_the_duplicate_values(cleaned_dataset):\n",
    "    '''\n",
    "    finding the duplicate rows but none is found\n",
    "    '''\n",
    "    duplicate=data.duplicated().sum()\n",
    "    \n",
    "def converting_categorical_into_numerical(cleaned_data):\n",
    "    '''\n",
    "    Converting categorical columns into numerical columns using encoding techniques\n",
    "    '''\n",
    "    encoder=LabelEncoder()\n",
    "    cleaned_data['rbc']=encoder.fit_transform(cleaned_data['rbc'].values)\n",
    "    cleaned_data['pc']=encoder.fit_transform(cleaned_data['pc'].values)\n",
    "    cleaned_data['pcc']=encoder.fit_transform(cleaned_data['pcc'].values)\n",
    "    cleaned_data['ba']=encoder.fit_transform(cleaned_data['ba'].values)\n",
    "    cleaned_data['pcv']=encoder.fit_transform(cleaned_data['pcv'].values)\n",
    "    cleaned_data['wc']=encoder.fit_transform(cleaned_data['wc'].values)\n",
    "    cleaned_data['rc']=encoder.fit_transform(cleaned_data['rc'].values)\n",
    "    cleaned_data['htn']=encoder.fit_transform(cleaned_data['htn'].values)\n",
    "    cleaned_data['dm']=encoder.fit_transform(cleaned_data['dm'].values)\n",
    "    cleaned_data['cad']=encoder.fit_transform(cleaned_data['cad'].values)\n",
    "    cleaned_data['appet']=encoder.fit_transform(cleaned_data['appet'].values)\n",
    "    cleaned_data['pe']=encoder.fit_transform(cleaned_data['pe'].values)\n",
    "    cleaned_data['ane']=encoder.fit_transform(cleaned_data['ane'].values)\n",
    "    return cleaned_data\n",
    "\n",
    "    \n",
    "def splitting_dataset_into_training_and_testing(cleaned_dataset):\n",
    "    '''\n",
    "    Splitting the given dataset into training and testing\n",
    "    '''\n",
    "    x=cleaned_dataset.drop(['classification'],axis=1)\n",
    "    y=cleaned_dataset['classification']\n",
    "    X_train,x_test,Y_train,y_test=train_test_split(x,y,test_size=0.40,random_state=24)\n",
    "    return X_train,x_test,Y_train,y_test\n",
    "   \n",
    "def oversampling_technique(X_train,Y_train):\n",
    "    '''\n",
    "    The dataset identified as imbalanced \n",
    "    class ckd has 248 data points and class 'not ckd' has 150 data points \n",
    "    '''\n",
    "    smote=SMOTE()\n",
    "    X_oversampled,y_oversampled=smote.fit_resample(X_train,Y_train)\n",
    "    return X_oversampled,y_oversampled\n",
    "\n",
    "\n",
    "\n",
    "def RandomForest_classifier(x_train,y_train,x_test,y_test):\n",
    "    '''\n",
    "    Fitting and testing the random forest classifier Model\n",
    "    '''\n",
    "    \n",
    "    rf_model=RandomForestClassifier()\n",
    "    rf_model=rf_model.fit(x_train,y_train)\n",
    "    y_predict=rf_model.predict(x_test)\n",
    "    conf_mat=confusion_matrix(y_true=y_test,y_pred=y_predict)\n",
    "    accuracy=accuracy_score(y_test,y_predict)*100\n",
    "    precision=precision_score(y_test,y_predict,average=None).mean()*100\n",
    "    recall=recall_score(y_test,y_predict,average=None).mean()*100\n",
    "    return rf_model,conf_mat,accuracy,precision,recall\n",
    "\n",
    "\n",
    "\n",
    "def knn_classifier_model(x_train,y_train,x_test,y_test):\n",
    "    knn=KNeighborsClassifier()\n",
    "    knn_model=knn.fit(x_train,y_train)\n",
    "    y_pred=knn_model.predict(x_test)\n",
    "    knn_conf_mat=confusion_matrix(y_true=y_test,y_pred=y_pred)\n",
    "    knn_accuracy=accuracy_score(y_test,y_pred)*100\n",
    "    knn_precision=precision_score(y_test,y_pred,average=None).mean()*100\n",
    "    knn_recall=recall_score(y_test,y_pred,average=None).mean()*100\n",
    "    return knn_model,knn_conf_mat,knn_accuracy,knn_precision,knn_recall\n",
    "    \n",
    "\n",
    "def logistic_regression_model(x_train,y_train,x_test,y_test):\n",
    "    logistic_regression_classifier=LogisticRegression()\n",
    "    logistic_model=logistic_regression_classifier.fit(x_train,y_train)\n",
    "    y_pred=logistic_model.predict(x_test)\n",
    "    logistic_conf_mat=confusion_matrix(y_true=y_test,y_pred=y_pred)\n",
    "    logistic_accuracy=accuracy_score(y_test,y_pred)*100\n",
    "    logistic_precision=precision_score(y_test,y_pred,average=None).mean()*100\n",
    "    logistic_recall=recall_score(y_test,y_pred,average=None).mean()*100\n",
    "    return logistic_model,logistic_conf_mat,logistic_accuracy,logistic_precision,logistic_recall\n",
    "    \n",
    "    \n",
    "def decision_tree_classifier(x_train,y_train,x_test,y_test):\n",
    "    DT=DecisionTreeClassifier()\n",
    "    DT_model=DT.fit(x_train,y_train)\n",
    "    y_pred=DT_model.predict(x_test)\n",
    "    DT_conf_mat=confusion_matrix(y_true=y_test,y_pred=y_pred)\n",
    "    DT_accuracy=accuracy_score(y_test,y_pred)*100\n",
    "    DT_precision=precision_score(y_test,y_pred,average=None).mean()*100\n",
    "    DT_recall=recall_score(y_test,y_pred,average=None).mean()*100\n",
    "    return DT_model,DT_conf_mat,DT_accuracy,DT_precision,DT_recall\n",
    "\n",
    "if __name__=='__main__':\n",
    "    data=data_reading()\n",
    "    dataset=finding_and_filling_null_values(data)\n",
    "    finding_the_duplicate_values(dataset)\n",
    "    print('Number of data points before oversampling method ',dataset['classification'].value_counts())\n",
    "    cleaned_dataset=converting_categorical_into_numerical(dataset)\n",
    "    X_train,x_test,Y_train,y_test=splitting_dataset_into_training_and_testing(cleaned_dataset)\n",
    "    #X_oversmapled,y_oversampled=oversampling_technique(X_train,Y_train)\n",
    "    print('#####################')\n",
    "    print('Number of training data points method ',X_train.shape)\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.heatmap(cleaned_dataset.corr(),annot=True)\n",
    "   \n",
    "    \n",
    "    knn_model,knn_conf_mat,knn_accuracy,knn_precision,knn_recall=knn_classifier_model(X_train,Y_train,x_test,y_test)\n",
    "    print('### KNN Model Accuracy Metrics ###')\n",
    "    sns.heatmap(knn_conf_mat, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    print('knn_model accuracy',int(knn_accuracy),'%')\n",
    "    print('knn_model precision',int(knn_precision),'%')\n",
    "    print('knn_model recall',int(knn_recall),'%')\n",
    "    \n",
    "    \n",
    "    logistic_model,logistic_conf_mat,logistic_accuracy,logistic_precision,logistic_recall=logistic_regression_model(X_train,Y_train,x_test,y_test)\n",
    "    print('### logistic Model Accuracy Metrics ###')\n",
    "    sns.heatmap(logistic_conf_mat, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    print('logistic_model accuracy',int(logistic_accuracy),'%')\n",
    "    print('logistic_model precision',int(logistic_precision),'%')\n",
    "    print('logistic_model recall',int(logistic_recall),'%')\n",
    "    \n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.heatmap(dataset.corr(),annot=True)\n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0b9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
